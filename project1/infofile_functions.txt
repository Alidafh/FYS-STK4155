Help on module functions:

NAME
    functions

FUNCTIONS
    FrankeFunction(x, y)
        Gives the values f(x,y) of the franke function
        --------------------------------
        Input
            x: numpy array or scalar
            y: numpy array or scalar
        --------------------------------
        Returns:
            z: numpy array or scalar representing the function value
        --------------------------------
        TO DO: FINISHED
    
    GenerateData(nData, noise_str=0, seed='')
        Generates three numpy arrays x, y, z of size (nData, 1).
        The x and y arrays are randomly distributed numbers between 0 and 1.
        The z array is created using the Franke Function with x and y, and if a
        noise_str is specified, random normally distributed noise with strength
        noise_str is added to the z-array.
        --------------------------------
        Input
            nData: number of datapoints
            noise_str: the strength of the noise, default is zero
            seed: if set to "debug" random numbers are the same for each turn
        --------------------------------
        Returns
            x: numpy array of shape (n,1) with random numbers between 0 and 1
            y: numpy arary of shape (n,1) with random numbers between 0 and 1
            z: numpy array of shape (n,1) with Franke function values f(x,y)
        --------------------------------
        TO DO: FINISHED
    
    OLS(z, X, var=False)
        Preforming ordinary least squares fit to find the regression parameters.
        If prompted it also calculates the variance of the fitted parameters.
        An error message will be printed if the design matrix has high
        dimentionality, p > n, but the parameters are still calculated.
        As this would give a negative variance, a temporary workaround is to take
        the absolute value of sigma^2.
        --------------------------------
        Input
            z: response variable
            X: Design matrix
            var: To calculate the variance set this to True (default is False)
        --------------------------------
        Returns
        - var=False
            beta: The estimated OLS regression parameters, shape (p,1)
            (var_beta: The variance of the parameters (p,1), returned if var=True)
        --------------------------------
        TODO: Find out if the absoultevalue thing in variance calculations is legit.
    
    OLS_SVD(z, X, var=False)
        Preforming ordinary least squares fit to find the regression parameters
        using a signgular value decomposition. Also, if prompted it calculates the
        variance of the fitted parameters
        --------------------------------
        Input
            z: response variable of shape (n,1) or (n,)
            X: Design matrix of shape (n,p)
            var: Bool. Set this to True to calculate the variance (default is False)
        --------------------------------
        Returns
            beta: The estimated OLS regression parameters shape (p,1)
            (var_beta: The variance of the parameters are returned if var=True)
        --------------------------------
        TO DO: FINISHED
    
    PolyDesignMatrix(x, y, d)
        Generates a design matrix of size (n,p) with monomials up to degree d as
        the columns. As an example if d=2 the columns of the design matrixs will be
        [1  x  y  x**2  y**2  xy].
        --------------------------------
        Input
            x: numpy array with shape (n,) or (n,1)
            y: numpy array with shape (n,) or (n,1)
            d: the degree of the polynomial (scalar)
        --------------------------------
        Returns
            X: Design matrix of shape (n, p)
        --------------------------------
        TO DO: FINISHED
    
    Ridge(z, X, lamb, var=False)
        Preforming Pridge regression to find the regression parameters. If prompted
        it calculates the variance of the fitted parameters.
        --------------------------------
        Input
            z: response variable
            X: design matrix
            lamb: penalty parameter
            var: to calculate the variance set this to True (default is False)
        --------------------------------
        Returns
            beta: The estimated Ridge regression parameters with shape (p,1)
            (var_beta: The variance of the parameters (p,1), returned if var=True)
            --------------------------------
        TODO: finish variance
    
    metrics(z_true, z_pred, test=False)
        Calculate the R^2 score, mean square error, variance and bias.
        If the predicted values has shape (n,1), it tests the calculated MSE and R2
        values against results from Scikitlearn. If the predicted values have shape
        (n,m) it checks that the calculated bias+variance <= MSE. Nothing is printed
        if you pass the test.
        --------------------------------
        Input
            z_true: The true response value
            z_approx: The approximation found using regression
            test: If you want to test the calculations (default is False)
        --------------------------------
        Returns
            R2, MSE, var, bias
        --------------------------------
        TODO: When using this with bootstrap, the calculated R2 score is waay off
              and when using it with kFold the bias and the MSE are identical
    
    scale_X(train, test)
        Scales the training and test data using sklearn's StandardScaler.
        --------------------------------
        Input
            train: The training set
            test:  The test set
        --------------------------------
        Returns
            train_scl: The scaled training set
            test_scl:  The scaled test set
        --------------------------------
        TO DO: FINISHED

FILE
    /home/alida/Documents/uio/Master/FYS-STK4155/project1/functions.py


