###############################################################################
# Set up the data
###############################################################################
type = "classification"

path = "../data/"
filename = "data_(200, 28, 28, 20)_1_0.008_0.0_0.0_10.0_1e+00_True_.npy"
data_file = path+filename
slice = None

#maps, labels, stats = load_data(file=data_file, slice=slice)

from generate import multiple_load_data
maps, labels, stats = multiple_load_data(data_file, slice, 10)

print(maps.shape)

(X_train, y_train), (X_test, y_test) = preprocess(maps, labels,
                                                train_size = 0.8,
                                                regress=True,
                                                scale=True,
                                                seed=42,
                                                shuffle=True)


#label_names = ["clean", "dm"]

###############################################################################
# for create_model()
###############################################################################
input_shape = (28, 28, 20)  # Shape of the images, holds the raw pixel values

n_filters = 16              # For the two first Conv2D layers
kernel_size = (5, 5)
layer_config = [32, 64]     # [layer1, layer2, layer3, ....] or None for no hidden layers
connected_neurons = 128     # For the first Dense layer

n_categories = 1            # For the last Dense layer (2 for GCE, 10 for mnist)

input_activation  = "relu"
hidden_activation = "relu"
output_activation = "sigmoid"

reg =  None #tf.keras.regularizers.l2(l=0.001)

###############################################################################
# for train_model()
###############################################################################
model_dir = "tmp/"           # Where to save the model

epochs = 50
batch_size = 10

opt = tf.keras.optimizers.Adam(learning_rate=1e-4)

reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=5, min_lr=1e-15)
early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)

loss = "binary_crossentropy"
metrics = ["accuracy"]




(ML) alida ~/Documents/uio/Master/FYS-STK4155/project3/code master(*&?) $ python CNN.py -cn clas10binary
(10000, 28, 28, 20)
________________________________________________________________

Analysis: classification
Save as:  clas10binary
________________________________________________________________

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 28, 28, 16)        8016
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 14, 14, 32)        12832
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 7, 7, 64)          51264
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0
_________________________________________________________________
flatten (Flatten)            (None, 576)               0
_________________________________________________________________
dense (Dense)                (None, 128)               73856
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 129
=================================================================
Total params: 146,097
Trainable params: 146,097
Non-trainable params: 0
_________________________________________________________________

training: 6400 - validation: 1600 - Untrained, accuracy: 48.19%
_________________________________________________________________

Epoch 1/50
512/512 [==============================] - 35s 67ms/step - loss: 0.6922 - accuracy: 0.5291 - val_loss: 0.7019 - val_accuracy: 0.4859 - lr: 1.0000e-04
Epoch 2/50
512/512 [==============================] - 30s 59ms/step - loss: 0.6871 - accuracy: 0.5385 - val_loss: 0.6770 - val_accuracy: 0.5422 - lr: 1.0000e-04
Epoch 3/50
512/512 [==============================] - 34s 67ms/step - loss: 0.6385 - accuracy: 0.6410 - val_loss: 0.5364 - val_accuracy: 0.8148 - lr: 1.0000e-04
Epoch 4/50
512/512 [==============================] - 36s 70ms/step - loss: 0.2862 - accuracy: 0.9211 - val_loss: 0.1311 - val_accuracy: 0.9570 - lr: 1.0000e-04
Epoch 5/50
512/512 [==============================] - 31s 60ms/step - loss: 0.0600 - accuracy: 0.9926 - val_loss: 0.0352 - val_accuracy: 1.0000 - lr: 1.0000e-04
Epoch 6/50
512/512 [==============================] - 33s 64ms/step - loss: 0.0261 - accuracy: 0.9969 - val_loss: 0.0201 - val_accuracy: 1.0000 - lr: 1.0000e-04
Epoch 7/50
512/512 [==============================] - 32s 62ms/step - loss: 0.0162 - accuracy: 0.9986 - val_loss: 0.0061 - val_accuracy: 1.0000 - lr: 1.0000e-04
Epoch 8/50
512/512 [==============================] - 32s 62ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000 - lr: 1.0000e-04
Epoch 9/50
512/512 [==============================] - 31s 60ms/step - loss: 0.0164 - accuracy: 0.9957 - val_loss: 0.0024 - val_accuracy: 1.0000 - lr: 1.0000e-04
Epoch 10/50
512/512 [==============================] - 29s 56ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000 - lr: 1.0000e-04
Epoch 11/50
512/512 [==============================] - 33s 65ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - lr: 1.0000e-04
Epoch 12/50
512/512 [==============================] - 35s 69ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.0021 - val_accuracy: 1.0000 - lr: 1.0000e-04
Epoch 13/50
512/512 [==============================] - 32s 63ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.4695e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04
Epoch 14/50
512/512 [==============================] - 33s 65ms/step - loss: 9.3446e-04 - accuracy: 1.0000 - val_loss: 6.2345e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04
Epoch 15/50
512/512 [==============================] - 33s 64ms/step - loss: 0.0867 - accuracy: 0.9793 - val_loss: 0.0018 - val_accuracy: 1.0000 - lr: 1.0000e-04
Epoch 16/50
512/512 [==============================] - 32s 63ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000 - lr: 1.0000e-04
Epoch 17/50
512/512 [==============================] - 33s 64ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 1.0000e-04
Epoch 18/50
512/512 [==============================] - 34s 66ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 9.7454e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04
Epoch 19/50
512/512 [==============================] - 34s 67ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 8.3035e-04 - val_accuracy: 1.0000 - lr: 1.0000e-04
Epoch 20/50
512/512 [==============================] - 32s 63ms/step - loss: 9.0394e-04 - accuracy: 1.0000 - val_loss: 8.0987e-04 - val_accuracy: 1.0000 - lr: 1.0000e-06
Epoch 21/50
512/512 [==============================] - 30s 58ms/step - loss: 8.9976e-04 - accuracy: 1.0000 - val_loss: 8.0847e-04 - val_accuracy: 1.0000 - lr: 1.0000e-06
Epoch 22/50
512/512 [==============================] - 30s 58ms/step - loss: 8.9773e-04 - accuracy: 1.0000 - val_loss: 8.0654e-04 - val_accuracy: 1.0000 - lr: 1.0000e-06
Epoch 23/50
512/512 [==============================] - 33s 64ms/step - loss: 8.9495e-04 - accuracy: 1.0000 - val_loss: 8.0204e-04 - val_accuracy: 1.0000 - lr: 1.0000e-06
Epoch 24/50
512/512 [==============================] - 34s 67ms/step - loss: 8.8944e-04 - accuracy: 1.0000 - val_loss: 8.1243e-04 - val_accuracy: 1.0000 - lr: 1.0000e-06
Epoch 25/50
512/512 [==============================] - 33s 64ms/step - loss: 8.9313e-04 - accuracy: 1.0000 - val_loss: 8.1222e-04 - val_accuracy: 1.0000 - lr: 1.0000e-08
Epoch 26/50
512/512 [==============================] - 32s 63ms/step - loss: 8.9296e-04 - accuracy: 1.0000 - val_loss: 8.1175e-04 - val_accuracy: 1.0000 - lr: 1.0000e-08
Epoch 27/50
512/512 [==============================] - 33s 64ms/step - loss: 8.9267e-04 - accuracy: 1.0000 - val_loss: 8.1114e-04 - val_accuracy: 1.0000 - lr: 1.0000e-08
Epoch 28/50
512/512 [==============================] - 34s 66ms/step - loss: 8.9227e-04 - accuracy: 1.0000 - val_loss: 8.1034e-04 - val_accuracy: 1.0000 - lr: 1.0000e-08
Epoch 29/50
512/512 [==============================] - 30s 59ms/step - loss: 8.9177e-04 - accuracy: 1.0000 - val_loss: 8.0896e-04 - val_accuracy: 1.0000 - lr: 1.0000e-08
Epoch 30/50
512/512 [==============================] - 33s 65ms/step - loss: 8.9130e-04 - accuracy: 1.0000 - val_loss: 8.0896e-04 - val_accuracy: 1.0000 - lr: 1.0000e-10
Epoch 31/50
512/512 [==============================] - 33s 64ms/step - loss: 8.9130e-04 - accuracy: 1.0000 - val_loss: 8.0896e-04 - val_accuracy: 1.0000 - lr: 1.0000e-10
Epoch 32/50
512/512 [==============================] - 34s 67ms/step - loss: 8.9130e-04 - accuracy: 1.0000 - val_loss: 8.0896e-04 - val_accuracy: 1.0000 - lr: 1.0000e-10
Epoch 33/50
512/512 [==============================] - 35s 68ms/step - loss: 8.9130e-04 - accuracy: 1.0000 - val_loss: 8.0896e-04 - val_accuracy: 1.0000 - lr: 1.0000e-10
Epoch 34/50
512/512 [==============================] - 31s 60ms/step - loss: 8.9130e-04 - accuracy: 1.0000 - val_loss: 8.0896e-04 - val_accuracy: 1.0000 - lr: 1.0000e-10
Epoch 35/50
512/512 [==============================] - 36s 70ms/step - loss: 8.9130e-04 - accuracy: 1.0000 - val_loss: 8.0896e-04 - val_accuracy: 1.0000 - lr: 1.0000e-12
Epoch 36/50
512/512 [==============================] - 31s 61ms/step - loss: 8.9130e-04 - accuracy: 1.0000 - val_loss: 8.0896e-04 - val_accuracy: 1.0000 - lr: 1.0000e-12
Epoch 37/50
512/512 [==============================] - 35s 68ms/step - loss: 8.9130e-04 - accuracy: 1.0000 - val_loss: 8.0896e-04 - val_accuracy: 1.0000 - lr: 1.0000e-12
Epoch 38/50
512/512 [==============================] - 33s 65ms/step - loss: 8.9130e-04 - accuracy: 1.0000 - val_loss: 8.0896e-04 - val_accuracy: 1.0000 - lr: 1.0000e-12
Epoch 39/50
512/512 [==============================] - 35s 68ms/step - loss: 8.9130e-04 - accuracy: 1.0000 - val_loss: 8.0896e-04 - val_accuracy: 1.0000 - lr: 1.0000e-12
Epoch 40/50
512/512 [==============================] - 35s 69ms/step - loss: 8.9130e-04 - accuracy: 1.0000 - val_loss: 8.0896e-04 - val_accuracy: 1.0000 - lr: 1.0000e-14
Epoch 41/50
512/512 [==============================] - 40s 79ms/step - loss: 8.9130e-04 - accuracy: 1.0000 - val_loss: 8.0896e-04 - val_accuracy: 1.0000 - lr: 1.0000e-14
Epoch 42/50
512/512 [==============================] - 40s 77ms/step - loss: 8.9130e-04 - accuracy: 1.0000 - val_loss: 8.0896e-04 - val_accuracy: 1.0000 - lr: 1.0000e-14
Epoch 43/50
512/512 [==============================] - 35s 68ms/step - loss: 8.9130e-04 - accuracy: 1.0000 - val_loss: 8.0896e-04 - val_accuracy: 1.0000 - lr: 1.0000e-14
Epoch 44/50
512/512 [==============================] - 34s 65ms/step - loss: 8.9130e-04 - accuracy: 1.0000 - val_loss: 8.0896e-04 - val_accuracy: 1.0000 - lr: 1.0000e-14
_________________________________________________________________

accuracy: 100.00%
_________________________________________________________________
