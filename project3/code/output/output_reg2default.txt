

###############################################################################
# Set up the data
###############################################################################

type = "regression"

path = "../data/"
filename = "maps_(10000, 28, 28, 20)_0.008_0.0_0.0_2.0_2.0e+15_True_.npy"
data_file = path+filename
slice = None

maps, labels, stats = load_data(file=data_file, slice=slice)

(X_train, y_train), (X_test, y_test) = preprocess(maps, labels,
                                                train_size = 0.8,
                                                regress=True,
                                                scale=True,
                                                seed=42,
                                                shuffle=True)


###############################################################################
# for create_model()
###############################################################################

input_shape = (28, 28, 20)     # Shape of the images, holds the raw pixel values

n_filters = 16                 # For the first Conv2D layer
kernel_size = (5, 5)
layer_config = [32, 64]        # (layer1, layer2, layer3, ....)

connected_neurons = 128        # For the first Dense layer
n_categories = 1               # For the last Dense layer

input_activation  = "relu"
hidden_activation = "relu"
output_activation = "sigmoid"

reg = None

###############################################################################
# for train_model()
###############################################################################

model_dir = "tmp/"           # Where to save the model

epochs = 50
batch_size = 10

opt = tf.keras.optimizers.Adam(learning_rate=1e-4)

# callbacks
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=5, min_lr=1e-15)
early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)

loss = "mean_squared_error"
metrics = [r2_score]



(ML) alida ~/Documents/uio/Master/FYS-STK4155/project3/code master(*&?) $ python CNN.py -rn reg2default
________________________________________________________________

Analysis: regression
Save as:  reg2default
________________________________________________________________

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 28, 28, 16)        8016
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 14, 14, 32)        12832
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 7, 7, 64)          51264
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0
_________________________________________________________________
flatten (Flatten)            (None, 576)               0
_________________________________________________________________
dense (Dense)                (None, 128)               73856
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 129
=================================================================
Total params: 146,097
Trainable params: 146,097
Non-trainable params: 0
_________________________________________________________________

training: 6400 - validation: 1600 - Untrained, r2_score: -3.46%
_________________________________________________________________

Epoch 1/50
512/512 [==============================] - 35s 68ms/step - loss: 0.0831 - r2_score: -0.1368 - val_loss: 0.0810 - val_r2_score: -0.1599 - lr: 1.0000e-04
Epoch 2/50
512/512 [==============================] - 35s 68ms/step - loss: 0.0831 - r2_score: -0.1382 - val_loss: 0.0810 - val_r2_score: -0.1591 - lr: 1.0000e-04
Epoch 3/50
512/512 [==============================] - 31s 61ms/step - loss: 0.0830 - r2_score: -0.1588 - val_loss: 0.0811 - val_r2_score: -0.1609 - lr: 1.0000e-04
Epoch 4/50
512/512 [==============================] - 43s 85ms/step - loss: 0.0831 - r2_score: -0.1635 - val_loss: 0.0809 - val_r2_score: -0.1583 - lr: 1.0000e-04
Epoch 5/50
512/512 [==============================] - 38s 73ms/step - loss: 0.0831 - r2_score: -0.1740 - val_loss: 0.0809 - val_r2_score: -0.1572 - lr: 1.0000e-04
Epoch 6/50
512/512 [==============================] - 37s 73ms/step - loss: 0.0829 - r2_score: -0.1277 - val_loss: 0.0803 - val_r2_score: -0.1491 - lr: 1.0000e-04
Epoch 7/50
512/512 [==============================] - 47s 91ms/step - loss: 0.0822 - r2_score: -0.1489 - val_loss: 0.0789 - val_r2_score: -0.1320 - lr: 1.0000e-04
Epoch 8/50
512/512 [==============================] - 41s 80ms/step - loss: 0.0765 - r2_score: -0.0711 - val_loss: 0.0727 - val_r2_score: -0.0576 - lr: 1.0000e-04
Epoch 9/50
512/512 [==============================] - 31s 61ms/step - loss: 0.0515 - r2_score: 0.2884 - val_loss: 0.0357 - val_r2_score: 0.4632 - lr: 1.0000e-04
Epoch 10/50
512/512 [==============================] - 34s 67ms/step - loss: 0.0341 - r2_score: 0.4968 - val_loss: 0.0274 - val_r2_score: 0.5722 - lr: 1.0000e-04
Epoch 11/50
512/512 [==============================] - 29s 56ms/step - loss: 0.0269 - r2_score: 0.6064 - val_loss: 0.0255 - val_r2_score: 0.5935 - lr: 1.0000e-04
Epoch 12/50
512/512 [==============================] - 31s 60ms/step - loss: 0.0239 - r2_score: 0.6453 - val_loss: 0.0188 - val_r2_score: 0.6987 - lr: 1.0000e-04
Epoch 13/50
512/512 [==============================] - 32s 62ms/step - loss: 0.0214 - r2_score: 0.6829 - val_loss: 0.0281 - val_r2_score: 0.5274 - lr: 1.0000e-04
Epoch 14/50
512/512 [==============================] - 30s 59ms/step - loss: 0.0209 - r2_score: 0.6865 - val_loss: 0.0163 - val_r2_score: 0.7360 - lr: 1.0000e-04
Epoch 15/50
512/512 [==============================] - 35s 69ms/step - loss: 0.0197 - r2_score: 0.7029 - val_loss: 0.0236 - val_r2_score: 0.6118 - lr: 1.0000e-04
Epoch 16/50
512/512 [==============================] - 43s 84ms/step - loss: 0.0184 - r2_score: 0.7180 - val_loss: 0.0146 - val_r2_score: 0.7635 - lr: 1.0000e-04
Epoch 17/50
512/512 [==============================] - 29s 56ms/step - loss: 0.0178 - r2_score: 0.7266 - val_loss: 0.0139 - val_r2_score: 0.7714 - lr: 1.0000e-04
Epoch 18/50
512/512 [==============================] - 36s 71ms/step - loss: 0.0175 - r2_score: 0.7288 - val_loss: 0.0136 - val_r2_score: 0.7773 - lr: 1.0000e-04
Epoch 19/50
512/512 [==============================] - 34s 66ms/step - loss: 0.0174 - r2_score: 0.7399 - val_loss: 0.0155 - val_r2_score: 0.7469 - lr: 1.0000e-04
Epoch 20/50
512/512 [==============================] - 30s 59ms/step - loss: 0.0157 - r2_score: 0.7580 - val_loss: 0.0155 - val_r2_score: 0.7386 - lr: 1.0000e-04
Epoch 21/50
512/512 [==============================] - 29s 57ms/step - loss: 0.0161 - r2_score: 0.7597 - val_loss: 0.0148 - val_r2_score: 0.7554 - lr: 1.0000e-04
Epoch 22/50
512/512 [==============================] - 30s 58ms/step - loss: 0.0154 - r2_score: 0.7670 - val_loss: 0.0131 - val_r2_score: 0.7797 - lr: 1.0000e-04
Epoch 23/50
512/512 [==============================] - 28s 55ms/step - loss: 0.0150 - r2_score: 0.7704 - val_loss: 0.0120 - val_r2_score: 0.8042 - lr: 1.0000e-04
Epoch 24/50
512/512 [==============================] - 28s 56ms/step - loss: 0.0146 - r2_score: 0.7833 - val_loss: 0.0134 - val_r2_score: 0.7794 - lr: 1.0000e-04
Epoch 25/50
512/512 [==============================] - 29s 57ms/step - loss: 0.0154 - r2_score: 0.7628 - val_loss: 0.0125 - val_r2_score: 0.7913 - lr: 1.0000e-04
Epoch 26/50
512/512 [==============================] - 31s 61ms/step - loss: 0.0148 - r2_score: 0.7817 - val_loss: 0.0195 - val_r2_score: 0.6751 - lr: 1.0000e-04
Epoch 27/50
512/512 [==============================] - 34s 67ms/step - loss: 0.0158 - r2_score: 0.7532 - val_loss: 0.0247 - val_r2_score: 0.5754 - lr: 1.0000e-04
Epoch 28/50
512/512 [==============================] - 36s 70ms/step - loss: 0.0137 - r2_score: 0.7958 - val_loss: 0.0110 - val_r2_score: 0.8155 - lr: 1.0000e-04
Epoch 29/50
512/512 [==============================] - 36s 70ms/step - loss: 0.0153 - r2_score: 0.7718 - val_loss: 0.0136 - val_r2_score: 0.7752 - lr: 1.0000e-04
Epoch 30/50
512/512 [==============================] - 34s 66ms/step - loss: 0.0136 - r2_score: 0.7882 - val_loss: 0.0108 - val_r2_score: 0.8203 - lr: 1.0000e-04
Epoch 31/50
512/512 [==============================] - 41s 80ms/step - loss: 0.0143 - r2_score: 0.7862 - val_loss: 0.0114 - val_r2_score: 0.8124 - lr: 1.0000e-04
Epoch 32/50
512/512 [==============================] - 38s 75ms/step - loss: 0.0138 - r2_score: 0.7861 - val_loss: 0.0108 - val_r2_score: 0.8207 - lr: 1.0000e-04
Epoch 33/50
512/512 [==============================] - 36s 70ms/step - loss: 0.0137 - r2_score: 0.7862 - val_loss: 0.0117 - val_r2_score: 0.8057 - lr: 1.0000e-04
Epoch 34/50
512/512 [==============================] - 32s 63ms/step - loss: 0.0133 - r2_score: 0.7990 - val_loss: 0.0121 - val_r2_score: 0.8002 - lr: 1.0000e-04
Epoch 35/50
512/512 [==============================] - 30s 58ms/step - loss: 0.0126 - r2_score: 0.8071 - val_loss: 0.0143 - val_r2_score: 0.7518 - lr: 1.0000e-04
Epoch 36/50
512/512 [==============================] - 32s 62ms/step - loss: 0.0106 - r2_score: 0.8359 - val_loss: 0.0104 - val_r2_score: 0.8259 - lr: 1.0000e-06
Epoch 37/50
512/512 [==============================] - 36s 71ms/step - loss: 0.0105 - r2_score: 0.8402 - val_loss: 0.0105 - val_r2_score: 0.8253 - lr: 1.0000e-06
Epoch 38/50
512/512 [==============================] - 39s 77ms/step - loss: 0.0105 - r2_score: 0.8371 - val_loss: 0.0104 - val_r2_score: 0.8256 - lr: 1.0000e-06
Epoch 39/50
512/512 [==============================] - 36s 71ms/step - loss: 0.0105 - r2_score: 0.8397 - val_loss: 0.0103 - val_r2_score: 0.8267 - lr: 1.0000e-06
Epoch 40/50
512/512 [==============================] - 34s 66ms/step - loss: 0.0105 - r2_score: 0.8435 - val_loss: 0.0104 - val_r2_score: 0.8248 - lr: 1.0000e-06
Epoch 41/50
512/512 [==============================] - 34s 67ms/step - loss: 0.0105 - r2_score: 0.8393 - val_loss: 0.0103 - val_r2_score: 0.8259 - lr: 1.0000e-06
Epoch 42/50
512/512 [==============================] - 30s 58ms/step - loss: 0.0105 - r2_score: 0.8413 - val_loss: 0.0103 - val_r2_score: 0.8265 - lr: 1.0000e-08
Epoch 43/50
512/512 [==============================] - 30s 59ms/step - loss: 0.0104 - r2_score: 0.8423 - val_loss: 0.0103 - val_r2_score: 0.8268 - lr: 1.0000e-08
Epoch 44/50
512/512 [==============================] - 31s 60ms/step - loss: 0.0104 - r2_score: 0.8372 - val_loss: 0.0103 - val_r2_score: 0.8270 - lr: 1.0000e-08
Epoch 45/50
512/512 [==============================] - 30s 58ms/step - loss: 0.0104 - r2_score: 0.8412 - val_loss: 0.0103 - val_r2_score: 0.8270 - lr: 1.0000e-08
Epoch 46/50
512/512 [==============================] - 31s 61ms/step - loss: 0.0104 - r2_score: 0.8438 - val_loss: 0.0103 - val_r2_score: 0.8270 - lr: 1.0000e-08
Epoch 47/50
512/512 [==============================] - 42s 82ms/step - loss: 0.0104 - r2_score: 0.8433 - val_loss: 0.0103 - val_r2_score: 0.8270 - lr: 1.0000e-08
Epoch 48/50
512/512 [==============================] - 41s 81ms/step - loss: 0.0104 - r2_score: 0.8421 - val_loss: 0.0103 - val_r2_score: 0.8270 - lr: 1.0000e-10
Epoch 49/50
512/512 [==============================] - 40s 79ms/step - loss: 0.0104 - r2_score: 0.8428 - val_loss: 0.0103 - val_r2_score: 0.8270 - lr: 1.0000e-10
Epoch 50/50
512/512 [==============================] - 37s 71ms/step - loss: 0.0104 - r2_score: 0.8382 - val_loss: 0.0103 - val_r2_score: 0.8270 - lr: 1.0000e-10
_________________________________________________________________

r2_score: 86.33%
_________________________________________________________________
