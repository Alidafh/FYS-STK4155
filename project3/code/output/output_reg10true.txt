#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Configureation file for the regression CNN
"""
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
import tensorflow.python.util.deprecation as deprecation
deprecation._PRINT_DEPRECATION_WARNINGS = False
import tensorflow as tf
from generate import load_data
from tools import preprocess, r2_score


###############################################################################
# Set up the data
###############################################################################

type = "regression"

path = "../data/"
filename = "maps_(10000, 28, 28, 20)_0.008_0.0_0.0_10.0_1.0e+00_True_.npy"
data_file = path+filename
slice = None

maps, labels, stats = load_data(file=data_file, slice=slice)

#from generate import multiple_load_data
#maps, labels, stats = multiple_load_data(data_file, slice, 100)


(X_train, y_train), (X_test, y_test) = preprocess(maps, labels,
                                                train_size = 0.8,
                                                regress=True,
                                                scale=True,
                                                seed=42,
                                                shuffle=True)


###############################################################################
# for create_model()
###############################################################################

input_shape = (28, 28, 20)     # Shape of the images, holds the raw pixel values

n_filters = 16                  # For the first Conv2D layer
kernel_size = (5,5)
layer_config = [32, 64]         # (layer1, layer2, layer3, ....)

connected_neurons = 128         # For the first Dense layer
n_categories = 1                # For the last Dense layer

input_activation  = "relu"
hidden_activation = "relu"
output_activation = "sigmoid"

reg = None  #tf.keras.regularizers.l2(l=0.1)

###############################################################################
# for train_model()
###############################################################################

model_dir = "tmp/"           # Where to save the model

epochs = 100
batch_size = 10

opt = tf.keras.optimizers.Adam(learning_rate=1e-4)

early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)

loss = "mean_squared_error"
metrics = [r2_score]






(ML) alida ~/Documents/uio/Master/FYS-STK4155/project3/code master(*&?) $ python CNN.py -rn reg10true
________________________________________________________________

Analysis: regression
Save as:  reg10true
________________________________________________________________

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 28, 28, 16)        8016
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 14, 14, 32)        12832
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 7, 7, 64)          51264
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0
_________________________________________________________________
flatten (Flatten)            (None, 576)               0
_________________________________________________________________
dense (Dense)                (None, 128)               73856
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 129
=================================================================
Total params: 146,097
Trainable params: 146,097
Non-trainable params: 0
_________________________________________________________________

training: 6400 - validation: 1600 - Untrained, r2_score: -4.94%
_________________________________________________________________

Epoch 1/100
512/512 [==============================] - 47s 92ms/step - loss: 0.0821 - r2_score: -0.1422 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 2/100
512/512 [==============================] - 36s 70ms/step - loss: 0.0821 - r2_score: -0.1354 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 3/100
512/512 [==============================] - 30s 58ms/step - loss: 0.0820 - r2_score: -0.1514 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 4/100
512/512 [==============================] - 29s 57ms/step - loss: 0.0820 - r2_score: -0.1648 - val_loss: 0.0877 - val_r2_score: -0.2184
Epoch 5/100
512/512 [==============================] - 28s 54ms/step - loss: 0.0820 - r2_score: -0.1428 - val_loss: 0.0877 - val_r2_score: -0.2185
Epoch 6/100
512/512 [==============================] - 29s 57ms/step - loss: 0.0820 - r2_score: -0.1448 - val_loss: 0.0877 - val_r2_score: -0.2184
Epoch 7/100
512/512 [==============================] - 31s 60ms/step - loss: 0.0820 - r2_score: -0.1539 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 8/100
512/512 [==============================] - 30s 59ms/step - loss: 0.0820 - r2_score: -0.1637 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 9/100
512/512 [==============================] - 32s 62ms/step - loss: 0.0820 - r2_score: -0.1503 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 10/100
512/512 [==============================] - 35s 68ms/step - loss: 0.0820 - r2_score: -0.1385 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 11/100
512/512 [==============================] - 28s 56ms/step - loss: 0.0820 - r2_score: -0.1714 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 12/100
512/512 [==============================] - 28s 55ms/step - loss: 0.0820 - r2_score: -0.1370 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 13/100
512/512 [==============================] - 30s 58ms/step - loss: 0.0820 - r2_score: -0.1453 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 14/100
512/512 [==============================] - 36s 70ms/step - loss: 0.0820 - r2_score: -0.1905 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 15/100
512/512 [==============================] - 35s 68ms/step - loss: 0.0820 - r2_score: -0.1333 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 16/100
512/512 [==============================] - 34s 66ms/step - loss: 0.0820 - r2_score: -0.1415 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 17/100
512/512 [==============================] - 34s 67ms/step - loss: 0.0820 - r2_score: -0.1549 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 18/100
512/512 [==============================] - 33s 64ms/step - loss: 0.0820 - r2_score: -0.1615 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 19/100
512/512 [==============================] - 32s 63ms/step - loss: 0.0820 - r2_score: -0.1574 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 20/100
512/512 [==============================] - 35s 69ms/step - loss: 0.0820 - r2_score: -0.1445 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 21/100
512/512 [==============================] - 38s 75ms/step - loss: 0.0820 - r2_score: -0.1779 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 22/100
512/512 [==============================] - 33s 65ms/step - loss: 0.0820 - r2_score: -0.1501 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 23/100
512/512 [==============================] - 33s 65ms/step - loss: 0.0820 - r2_score: -0.1484 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 24/100
512/512 [==============================] - 35s 69ms/step - loss: 0.0820 - r2_score: -0.1567 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 25/100
512/512 [==============================] - 36s 71ms/step - loss: 0.0820 - r2_score: -0.1452 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 26/100
512/512 [==============================] - 31s 61ms/step - loss: 0.0820 - r2_score: -0.1466 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 27/100
512/512 [==============================] - 28s 55ms/step - loss: 0.0820 - r2_score: -0.1482 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 28/100
512/512 [==============================] - 29s 56ms/step - loss: 0.0820 - r2_score: -0.1554 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 29/100
512/512 [==============================] - 31s 60ms/step - loss: 0.0820 - r2_score: -0.1417 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 30/100
512/512 [==============================] - 39s 77ms/step - loss: 0.0820 - r2_score: -0.1515 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 31/100
512/512 [==============================] - 34s 67ms/step - loss: 0.0820 - r2_score: -0.1578 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 32/100
512/512 [==============================] - 33s 64ms/step - loss: 0.0820 - r2_score: -0.1550 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 33/100
512/512 [==============================] - 33s 64ms/step - loss: 0.0820 - r2_score: -0.1416 - val_loss: 0.0877 - val_r2_score: -0.2183
Epoch 34/100
512/512 [==============================] - 31s 60ms/step - loss: 0.0820 - r2_score: -0.1709 - val_loss: 0.0877 - val_r2_score: -0.2183
_________________________________________________________________

r2_score: -4.42%
_________________________________________________________________
